{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dfu5823/ONM-Outcomes/blob/main/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/dfu5823/ONM-Outcomes.git"
      ],
      "metadata": {
        "collapsed": true,
        "id": "eUrUGmQfy3hG"
      },
      "id": "eUrUGmQfy3hG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install cloudpickle numpy pandas scikit-learn gradio catboost shap plotly"
      ],
      "metadata": {
        "collapsed": true,
        "id": "VEc1Ru-AqzDI"
      },
      "id": "VEc1Ru-AqzDI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5661b49c",
      "metadata": {
        "collapsed": true,
        "id": "5661b49c"
      },
      "outputs": [],
      "source": [
        "# Imports and Load Model\n",
        "\n",
        "# --- core ---\n",
        "import os, re, io, json, time, warnings, math, zipfile, requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Optional, Dict, Tuple\n",
        "import cloudpickle\n",
        "\n",
        "# --- model / explainability ---\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "import shap\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# --- app ---\n",
        "import gradio as gr\n",
        "\n",
        "MODEL_DIR = \"ONM-Outcomes/models/\"\n",
        "\n",
        "with open(os.path.join(MODEL_DIR, \"30d_mort_demo_trained_stacked_model.pkl\"), \"rb\") as f:\n",
        "    stacked_model = cloudpickle.load(f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "188322f4",
      "metadata": {
        "id": "188322f4"
      },
      "outputs": [],
      "source": [
        "# # Create feature mapping\n",
        "# ------------------------------- #\n",
        "# Final feature list (exact order)\n",
        "# ------------------------------- #\n",
        "selected_features = [\n",
        "    'AGE',\n",
        "    'CROWFLY',\n",
        "    'YEAR_OF_DIAGNOSIS',\n",
        "    'REGIONAL_NODES_POSITIVE',\n",
        "    'TUMOR_SIZE_SUMMARY_16',\n",
        "    'TUMOR_SIZE',\n",
        "    'DX_SURG_STARTED_DAYS',\n",
        "    'DX_DEFSURG_STARTED_DAYS',\n",
        "    'SURG_DISCHARGE_DAYS',\n",
        "    'REGIONAL_NODES_EXAMINED',\n",
        "\n",
        "    # ZIP-derived (auto)\n",
        "    'NO_HSD_QUAR_00',\n",
        "    'NO_HSD_QUAR_12',\n",
        "    'NO_HSD_QUAR_2016',\n",
        "    'MED_INC_QUAR_00',\n",
        "    'MED_INC_QUAR_12',\n",
        "    'MED_INC_QUAR_2016',\n",
        "    'UR_CD_03',\n",
        "    'UR_CD_13',\n",
        "\n",
        "    # Clinico-demographic\n",
        "    'CDCC_TOTAL_BEST',\n",
        "    'BEHAVIOR',\n",
        "\n",
        "    # Race (collapsed to White/Black/Other)\n",
        "    'RACE_1.0',   # White\n",
        "    'RACE_2.0',   # Black\n",
        "\n",
        "    # Sex (two cols per spec)\n",
        "    'SEX_1.0',  # Male\n",
        "    'SEX_2.0',  # Female\n",
        "\n",
        "    # Facility Type (one-hot + nan)\n",
        "    'FACILITY_TYPE_CD_1.0',\n",
        "    'FACILITY_TYPE_CD_2.0',\n",
        "    'FACILITY_TYPE_CD_3.0',\n",
        "    'FACILITY_TYPE_CD_4.0',\n",
        "    'FACILITY_TYPE_CD_nan',\n",
        "\n",
        "    # Clinical Stage Group (you listed both a base token and specific one-hots)\n",
        "    'TNM_CLIN_STAGE_GROUP_',\n",
        "    'TNM_CLIN_STAGE_GROUP_   0',\n",
        "    'TNM_CLIN_STAGE_GROUP_   1',\n",
        "    'TNM_CLIN_STAGE_GROUP_   2',\n",
        "    'TNM_CLIN_STAGE_GROUP_   3',\n",
        "    'TNM_CLIN_STAGE_GROUP_   4',\n",
        "    'TNM_CLIN_STAGE_GROUP_  4A',\n",
        "    'TNM_CLIN_STAGE_GROUP_  4B',\n",
        "    'TNM_CLIN_STAGE_GROUP_  4C',\n",
        "    'TNM_CLIN_STAGE_GROUP_  99',\n",
        "\n",
        "    'RACE_OTHER', # All other races collapsed\n",
        "]\n",
        "\n",
        "# ------------------------------- #\n",
        "# Defaults\n",
        "# ------------------------------- #\n",
        "default_values = {\n",
        "    \"AGE\": 65,\n",
        "    \"CROWFLY\": 10.0,\n",
        "    \"YEAR_OF_DIAGNOSIS\": 2015,\n",
        "    \"REGIONAL_NODES_POSITIVE\": 1,\n",
        "    \"TUMOR_SIZE\": 30,                 # mm\n",
        "    \"DX_SURG_STARTED_DAYS\": 14,\n",
        "    \"DX_DEFSURG_STARTED_DAYS\": 21,\n",
        "    \"SURG_DISCHARGE_DAYS\": 5,\n",
        "    \"REGIONAL_NODES_EXAMINED\": 10,\n",
        "    \"CDCC_TOTAL_BEST\": 0,\n",
        "    # ZIP-derived defaults if lookup fails (None -> we'll fallback to mid bins)\n",
        "    \"NO_HSD_QUAR_00\": 2,\n",
        "    \"NO_HSD_QUAR_12\": 2,\n",
        "    \"NO_HSD_QUAR_2016\": 2,\n",
        "    \"MED_INC_QUAR_00\": 3,\n",
        "    \"MED_INC_QUAR_12\": 3,\n",
        "    \"MED_INC_QUAR_2016\": 3,\n",
        "    \"UR_CD_03\": 2,\n",
        "    \"UR_CD_13\": 2,\n",
        "    # Behavior default (invasive = 3 is typical for cancers captured in NCDB)\n",
        "    \"BEHAVIOR\": 3,\n",
        "}\n",
        "\n",
        "# ------------------------------- #\n",
        "# Controlled-value dropdown maps\n",
        "# ------------------------------- #\n",
        "RACE_UI_TO_ONEHOT = {\n",
        "    \"White\":  (\"RACE_1.0\",),\n",
        "    \"Black\":  (\"RACE_2.0\",),\n",
        "    \"Other\":  (\"RACE_OTHER\",),\n",
        "}\n",
        "\n",
        "SEX_UI_TO_ONEHOT = {\n",
        "    \"M\": (\"SEX_1.0\",),\n",
        "    \"F\": (\"SEX_2.0\",),\n",
        "    \"Other / Unknown\": tuple(),  # both 0\n",
        "}\n",
        "\n",
        "FACILITY_TYPE_UI_TO_ONEHOT = {\n",
        "    \"Community Cancer Program\":               (\"FACILITY_TYPE_CD_1.0\",),\n",
        "    \"Comprehensive Community Cancer Program\": (\"FACILITY_TYPE_CD_2.0\",),\n",
        "    \"Academic/Research Program\":              (\"FACILITY_TYPE_CD_3.0\",),\n",
        "    \"Integrated Network Cancer Program\":      (\"FACILITY_TYPE_CD_4.0\",),\n",
        "    \"Not available\":                          (\"FACILITY_TYPE_CD_nan\",),\n",
        "}\n",
        "\n",
        "CLIN_STAGE_UI_TO_ONEHOT = {\n",
        "    \"Stage 0\":   \"TNM_CLIN_STAGE_GROUP_   0\",\n",
        "    \"Stage 1\":   \"TNM_CLIN_STAGE_GROUP_   1\",\n",
        "    \"Stage 2\":   \"TNM_CLIN_STAGE_GROUP_   2\",\n",
        "    \"Stage 3\":   \"TNM_CLIN_STAGE_GROUP_   3\",\n",
        "    \"Stage 4\":   \"TNM_CLIN_STAGE_GROUP_   4\",\n",
        "    \"Stage 4A\":  \"TNM_CLIN_STAGE_GROUP_  4A\",\n",
        "    \"Stage 4B\":  \"TNM_CLIN_STAGE_GROUP_  4B\",\n",
        "    \"Stage 4C\":  \"TNM_CLIN_STAGE_GROUP_  4C\",\n",
        "    \"Unknown\":   \"TNM_CLIN_STAGE_GROUP_  99\",\n",
        "}\n",
        "\n",
        "# Behavior code (0-3) — show descriptive labels to user, map back to code\n",
        "BEHAVIOR_UI_TO_CODE = {\n",
        "    \"Benign\": 0,\n",
        "    \"Borderline / Uncertain\": 1,\n",
        "    \"In-situ\": 2,\n",
        "    \"Invasive\": 3,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import shap\n",
        "\n",
        "# ---- baseline prevalence (given) ----\n",
        "BASELINE_PREVALENCE = 284 / 32764  # ~0.866%\n",
        "\n",
        "def odds_ratio_vs_baseline(p: float, p0: float = BASELINE_PREVALENCE) -> float:\n",
        "    p  = float(np.clip(p,  1e-8, 1 - 1e-8))\n",
        "    p0 = float(np.clip(p0, 1e-8, 1 - 1e-8))\n",
        "    return (p / (1 - p)) / (p0 / (1 - p0))\n",
        "\n",
        "# ---------------------- background loader (pickle + cache) ----------------\n",
        "_SHAP_BG_CACHE = {\"X\": None, \"path\": None}\n",
        "\n",
        "def load_shap_background(expected_cols, path: str = \"ONM-Outcomes/models/shap_background.pkl\"):\n",
        "    \"\"\"\n",
        "    Load a precomputed model-ready background matrix from a pickle file\n",
        "    and align it to expected_cols. No background generation here.\n",
        "    \"\"\"\n",
        "    # cached?\n",
        "    if _SHAP_BG_CACHE[\"X\"] is not None and _SHAP_BG_CACHE[\"path\"] == path:\n",
        "        return _SHAP_BG_CACHE[\"X\"].reindex(columns=expected_cols).fillna(0.0)\n",
        "\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(\n",
        "            f\"SHAP background pickle not found at '{path}'. \"\n",
        "            f\"Please create it (e.g., with pickle.dump(Xbg, open('{path}','wb'))).\"\n",
        "        )\n",
        "\n",
        "    with open(path, \"rb\") as f:\n",
        "        Xbg = pickle.load(f)\n",
        "\n",
        "    # Align & cast numerics to float to avoid dtype warnings\n",
        "    Xbg = pd.DataFrame(Xbg)  # in case a numpy array was saved\n",
        "    Xbg = Xbg.reindex(columns=expected_cols).fillna(0.0)\n",
        "    num_cols = Xbg.select_dtypes(include=[np.number]).columns\n",
        "    Xbg[num_cols] = Xbg[num_cols].astype(float)\n",
        "\n",
        "    # Keep small for speed (tweak as you like)\n",
        "    if len(Xbg) > 500:\n",
        "        Xbg = Xbg.sample(500, random_state=42)\n",
        "\n",
        "    _SHAP_BG_CACHE[\"X\"] = Xbg\n",
        "    _SHAP_BG_CACHE[\"path\"] = path\n",
        "    return Xbg\n",
        "\n",
        "# ---------------- feature grouping (for readable bars) --------------------\n",
        "def build_group_map(feature_cols: list[str]) -> dict[str, list[str]]:\n",
        "    groups = {\n",
        "        \"ZIP: Education (No HS)\": [c for c in feature_cols if c.startswith(\"NO_HSD_QUAR_\")],\n",
        "        \"ZIP: Median Income\":     [c for c in feature_cols if c.startswith(\"MED_INC_QUAR_\")],\n",
        "        \"ZIP: Urban/Rural\":       [c for c in feature_cols if c.startswith(\"UR_CD_\")],\n",
        "        \"Clinical Stage Group\":   [c for c in feature_cols if c.startswith(\"TNM_CLIN_STAGE_GROUP_\")],\n",
        "        \"Race\":                   [c for c in feature_cols if c.startswith(\"RACE_\")],\n",
        "        \"Sex\":                    [c for c in feature_cols if c.startswith(\"SEX_\")],\n",
        "        \"Facility Type\":          [c for c in feature_cols if c.startswith(\"FACILITY_TYPE_CD_\")],\n",
        "        \"Regional Nodes (pos/exam)\": [c for c in feature_cols if c in (\"REGIONAL_NODES_POSITIVE\", \"REGIONAL_NODES_EXAMINED\")],\n",
        "        \"Timing (Dx→Surg/DefSurg/Discharge)\": [\n",
        "            c for c in feature_cols if c in (\"DX_SURG_STARTED_DAYS\", \"DX_DEFSURG_STARTED_DAYS\", \"SURG_DISCHARGE_DAYS\")\n",
        "        ],\n",
        "        \"Tumor Size\":             [c for c in feature_cols if c in (\"TUMOR_SIZE\", \"TUMOR_SIZE_SUMMARY_16\")],\n",
        "        \"Age\":                    [\"AGE\"],\n",
        "        \"Distance to Hospital\":   [\"CROWFLY\"],\n",
        "        \"Year of Diagnosis\":      [\"YEAR_OF_DIAGNOSIS\"],\n",
        "        \"Charlson/Deyo\":          [\"CDCC_TOTAL_BEST\"],\n",
        "        \"Behavior\":               [\"BEHAVIOR\"],\n",
        "    }\n",
        "    # Show any stray columns individually\n",
        "    used = set(sum(groups.values(), []))\n",
        "    for c in feature_cols:\n",
        "        if c not in used:\n",
        "            groups[c] = [c]\n",
        "    return groups\n",
        "\n",
        "# --------------- SHAP (KernelExplainer) on the calibrated stacker --------\n",
        "def shap_grouped_bar_kernel(model, df_row: pd.DataFrame, bg_pickle_path: str = \"shap_background.pkl\", max_display=12):\n",
        "    \"\"\"\n",
        "    Pure black-box SHAP on your calibrated stacked model (no XGBoost references).\n",
        "    Uses ONLY the precomputed pickle background (no on-the-fly generation).\n",
        "    \"\"\"\n",
        "    assert isinstance(df_row, pd.DataFrame) and len(df_row) == 1, \"df_row must be a 1-row DataFrame\"\n",
        "    cols = list(df_row.columns)\n",
        "\n",
        "    # Load & align background from pickle\n",
        "    Xbg = load_shap_background(cols, path=bg_pickle_path)\n",
        "    if len(Xbg) > 256:  # extra speed guard\n",
        "        Xbg = Xbg.sample(256, random_state=42)\n",
        "\n",
        "    # Probability function\n",
        "    def proba_fn(x):\n",
        "        Xdf = pd.DataFrame(x, columns=cols)\n",
        "        return model.predict_proba(Xdf)[:, 1]\n",
        "\n",
        "    # Kernel SHAP on log-odds\n",
        "    explainer = shap.KernelExplainer(proba_fn, Xbg, link=\"logit\")\n",
        "    sv = explainer.shap_values(df_row, nsamples=\"auto\")\n",
        "    shap_vals = np.asarray(sv)\n",
        "    if shap_vals.ndim == 2 and shap_vals.shape[0] == 1 and shap_vals.shape[1] == len(cols):\n",
        "        shap_vals = shap_vals[0]\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected SHAP shape {shap_vals.shape}, expected (1, {len(cols)})\")\n",
        "\n",
        "    # Group to user-level concepts\n",
        "    group_map = build_group_map(cols)\n",
        "    sv_series = pd.Series(shap_vals, index=cols)\n",
        "    grouped = {g: float(sv_series[v].sum()) for g, v in group_map.items() if any(c in cols for c in v)}\n",
        "\n",
        "    # Top impacts\n",
        "    imp = pd.Series(grouped).abs().sort_values(ascending=False)\n",
        "    top = imp.head(max_display).index\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 5))\n",
        "    signed = pd.Series(grouped)[top]\n",
        "    ax.barh(range(len(top)), signed.values)\n",
        "    ax.set_yticks(range(len(top)))\n",
        "    ax.set_yticklabels(top)\n",
        "    ax.set_xlabel(\"SHAP value (impact on log-odds)\")\n",
        "    ax.set_title(\"What drove this prediction?\")\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    return fig\n"
      ],
      "metadata": {
        "id": "6LwQTG9mlFN7"
      },
      "id": "6LwQTG9mlFN7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Census data helpers\n",
        "\n",
        "# ------------------------------- #\n",
        "# Census / RUCC helpers (ZIP → 8 vars)\n",
        "# ------------------------------- #\n",
        "CENSUS_BASE = \"https://api.census.gov/data\"\n",
        "CENSUS_API_KEY = os.environ.get(\"CENSUS_API_KEY\", None)  # optional\n",
        "\n",
        "def _get(url: str, params: dict, tries: int = 3, sleep: float = 0.7):\n",
        "    for _ in range(tries):\n",
        "        r = requests.get(url, params=params, timeout=30)\n",
        "        if r.ok:\n",
        "            return r\n",
        "        time.sleep(sleep)\n",
        "    r.raise_for_status()\n",
        "\n",
        "def _as_float(x) -> Optional[float]:\n",
        "    if x is None:\n",
        "        return None\n",
        "    s = str(x)\n",
        "    m = re.search(r\"[-+]?\\d+(\\.\\d+)?\", s)\n",
        "    return float(m.group(0)) if m else None\n",
        "\n",
        "def _zip_to_zcta(zip5: str) -> str:\n",
        "    if not re.fullmatch(r\"\\d{5}\", zip5):\n",
        "        raise ValueError(\"ZIP must be 5 digits.\")\n",
        "    return zip5\n",
        "\n",
        "def _hud_zip_county_crosswalk() -> pd.DataFrame:\n",
        "    url = \"https://www.huduser.gov/portal/datasets/usps_crosswalk.html\"\n",
        "    html = requests.get(url, timeout=30).text\n",
        "    m = re.search(r'href=\"([^\"]+zip_county[^\"]+\\.csv)\"', html, flags=re.I)\n",
        "    if not m:\n",
        "        raise RuntimeError(\"Could not locate HUD ZIP–County CSV link.\")\n",
        "    csv_url = m.group(1)\n",
        "    if csv_url.startswith(\"/\"):\n",
        "        csv_url = \"https://www.huduser.gov\" + csv_url\n",
        "    df = pd.read_csv(csv_url, dtype={\"ZIP\": str, \"COUNTY\": str})\n",
        "    keep = [c for c in [\"ZIP\", \"COUNTY\", \"RES_RATIO\"] if c in df.columns]\n",
        "    return df[keep]\n",
        "\n",
        "def _dominant_county_for_zip(zip5: str) -> str:\n",
        "    xw = _hud_zip_county_crosswalk()\n",
        "    sub = xw[xw[\"ZIP\"] == zip5]\n",
        "    if sub.empty:\n",
        "        sub = xw[xw[\"ZIP\"] == str(int(zip5)).zfill(5)]\n",
        "    if sub.empty:\n",
        "        raise ValueError(f\"No county mapping found for ZIP {zip5}\")\n",
        "    row = sub.sort_values(\"RES_RATIO\", ascending=False).iloc[0]\n",
        "    return row[\"COUNTY\"]  # 5-digit county FIPS\n",
        "\n",
        "def _load_rucc_2003_2013() -> pd.DataFrame:\n",
        "    url = (\"https://seer.cancer.gov/seerstat/variables/countyattribs/\"\n",
        "           \"Rural.Urban.Continuum.Codes.1974.1983.1993.2003.2013.2023.xlsx\")\n",
        "    data = requests.get(url, timeout=60).content\n",
        "    df = pd.read_excel(io.BytesIO(data), engine=\"openpyxl\", dtype={\"FIPS\": str})\n",
        "    cols = {c: c for c in df.columns}\n",
        "    for c in list(df.columns):\n",
        "        lc = c.lower()\n",
        "        if \"rural-urban continuum code 2003\" in lc:\n",
        "            cols[c] = \"RUCC_2003\"\n",
        "        if \"rural-urban continuum code 2013\" in lc:\n",
        "            cols[c] = \"RUCC_2013\"\n",
        "    df = df.rename(columns=cols)\n",
        "    need = [\"FIPS\", \"RUCC_2003\", \"RUCC_2013\"]\n",
        "    missing = [c for c in need if c not in df.columns]\n",
        "    if missing:\n",
        "        raise RuntimeError(f\"RUCC columns missing: {missing}\")\n",
        "    df[\"FIPS\"] = df[\"FIPS\"].str.zfill(5)\n",
        "    return df[need]\n",
        "\n",
        "def _rucc_for_county(county_fips: str) -> Tuple[Optional[int], Optional[int]]:\n",
        "    rucc = _load_rucc_2003_2013()\n",
        "    row = rucc[rucc[\"FIPS\"] == county_fips]\n",
        "    if row.empty:\n",
        "        return None, None\n",
        "    r = row.iloc[0]\n",
        "    v03 = int(r[\"RUCC_2003\"]) if not pd.isna(r[\"RUCC_2003\"]) else None\n",
        "    v13 = int(r[\"RUCC_2013\"]) if not pd.isna(r[\"RUCC_2013\"]) else None\n",
        "    return v03, v13\n",
        "\n",
        "# Education → quartiles\n",
        "def _edu_quartile_2000(percent_no_hs: float) -> int:\n",
        "    if percent_no_hs >= 29.0: return 1\n",
        "    if percent_no_hs >= 20.0: return 2\n",
        "    if percent_no_hs >= 14.0: return 3\n",
        "    return 4\n",
        "\n",
        "def _edu_quartile_2012(percent_no_hs: float) -> int:\n",
        "    if percent_no_hs >= 21.0: return 1\n",
        "    if percent_no_hs >= 13.0: return 2\n",
        "    if percent_no_hs >= 7.0:  return 3\n",
        "    return 4\n",
        "\n",
        "def _edu_quartile_2016(percent_no_hs: float) -> int:\n",
        "    if percent_no_hs >= 17.6: return 1\n",
        "    if percent_no_hs >= 10.9: return 2\n",
        "    if percent_no_hs >= 6.3:  return 3\n",
        "    return 4\n",
        "\n",
        "# Income → quartiles\n",
        "def _inc_quartile_2000(median_income_1999_usd: float) -> int:\n",
        "    if median_income_1999_usd < 30000: return 1\n",
        "    if median_income_1999_usd <= 34999: return 2\n",
        "    if median_income_1999_usd <= 45999: return 3\n",
        "    return 4\n",
        "\n",
        "def _inc_quartile_2012(median_income_2012usd: float) -> int:\n",
        "    if median_income_2012usd < 38000: return 1\n",
        "    if median_income_2012usd <= 47999: return 2\n",
        "    if median_income_2012usd <= 62999: return 3\n",
        "    return 4\n",
        "\n",
        "def _inc_quartile_2016(median_income_2016usd: float) -> int:\n",
        "    if median_income_2016usd < 40227: return 1\n",
        "    if median_income_2016usd <= 50353: return 2\n",
        "    if median_income_2016usd <= 63332: return 3\n",
        "    return 4\n",
        "\n",
        "# Census pulls\n",
        "def _edu_pct_no_hs_2000(zcta: str) -> Optional[float]:\n",
        "    url = f\"{CENSUS_BASE}/2000/dec/sf3profile\"\n",
        "    # Try numeric cell, then labeled cell\n",
        "    for var in [\"DP2_C28A0\", \"DP2_E1\"]:\n",
        "        try:\n",
        "            params = {\"get\": var, \"for\": f\"zip%20code%20tabulation%20area:{zcta}\"}\n",
        "            if CENSUS_API_KEY: params[\"key\"] = CENSUS_API_KEY\n",
        "            r = _get(url, params=params)\n",
        "            vals = r.json()[1][0]\n",
        "            pct_hs_plus = _as_float(vals)\n",
        "            if pct_hs_plus is not None:\n",
        "                return max(0.0, 100.0 - pct_hs_plus)\n",
        "        except Exception:\n",
        "            continue\n",
        "    return None\n",
        "\n",
        "def _edu_pct_no_hs_acs(zcta: str, vintage: int) -> Optional[float]:\n",
        "    url = f\"{CENSUS_BASE}/{vintage}/acs/acs5/profile\"\n",
        "    params = {\"get\": \"DP02_0067PE\", \"for\": f\"zip%20code%20tabulation%20area:{zcta}\"}\n",
        "    if CENSUS_API_KEY: params[\"key\"] = CENSUS_API_KEY\n",
        "    r = _get(url, params=params)\n",
        "    pct_hs_plus = _as_float(r.json()[1][0])\n",
        "    return max(0.0, 100.0 - pct_hs_plus) if pct_hs_plus is not None else None\n",
        "\n",
        "def _median_income_2000(zcta: str) -> Optional[float]:\n",
        "    url = f\"{CENSUS_BASE}/2000/dec/sf3profile\"\n",
        "    params = {\"get\": \"DP3_C112\", \"for\": f\"zip%20code%20tabulation%20area:{zcta}\"}\n",
        "    if CENSUS_API_KEY: params[\"key\"] = CENSUS_API_KEY\n",
        "    r = _get(url, params=params)\n",
        "    return _as_float(r.json()[1][0])\n",
        "\n",
        "def _median_income_acs(zcta: str, vintage: int) -> Optional[float]:\n",
        "    url = f\"{CENSUS_BASE}/{vintage}/acs/acs5/profile\"\n",
        "    params = {\"get\": \"DP03_0062E\", \"for\": f\"zip%20code%20tabulation%20area:{zcta}\"}\n",
        "    if CENSUS_API_KEY: params[\"key\"] = CENSUS_API_KEY\n",
        "    r = _get(url, params=params)\n",
        "    return _as_float(r.json()[1][0])\n",
        "\n",
        "def ncdb_zip_to_vars(zip5: str) -> Dict[str, Optional[int]]:\n",
        "    \"\"\"\n",
        "    Return NCDB-style sociodemographic vars from 5-digit ZIP:\n",
        "    NO_HSD_QUAR_00/12/2016, MED_INC_QUAR_00/12/2016, UR_CD_03/13.\n",
        "    \"\"\"\n",
        "    zcta = _zip_to_zcta(str(zip5))\n",
        "\n",
        "    # Education (percent no HS → bins)\n",
        "    p_nohs_00 = _edu_pct_no_hs_2000(zcta)\n",
        "    p_nohs_12 = _edu_pct_no_hs_acs(zcta, 2012)\n",
        "    p_nohs_16 = _edu_pct_no_hs_acs(zcta, 2016)\n",
        "    NO_HSD_QUAR_00 = _edu_quartile_2000(p_nohs_00) if p_nohs_00 is not None else None\n",
        "    NO_HSD_QUAR_12 = _edu_quartile_2012(p_nohs_12) if p_nohs_12 is not None else None\n",
        "    NO_HSD_QUAR_2016 = _edu_quartile_2016(p_nohs_16) if p_nohs_16 is not None else None\n",
        "\n",
        "    # Income (median → bins)\n",
        "    inc00 = _median_income_2000(zcta)    # 1999 dollars\n",
        "    inc12 = _median_income_acs(zcta, 2012)  # 2012 $\n",
        "    inc16 = _median_income_acs(zcta, 2016)  # 2016 $\n",
        "    MED_INC_QUAR_00 = _inc_quartile_2000(inc00) if inc00 is not None else None\n",
        "    MED_INC_QUAR_12 = _inc_quartile_2012(inc12) if inc12 is not None else None\n",
        "    MED_INC_QUAR_2016 = _inc_quartile_2016(inc16) if inc16 is not None else None\n",
        "\n",
        "    # RUCC (county-based)\n",
        "    try:\n",
        "        county_fips = _dominant_county_for_zip(zcta)\n",
        "        rucc03, rucc13 = _rucc_for_county(county_fips)\n",
        "    except Exception:\n",
        "        rucc03, rucc13 = None, None\n",
        "\n",
        "    return {\n",
        "        \"NO_HSD_QUAR_00\": NO_HSD_QUAR_00,\n",
        "        \"NO_HSD_QUAR_12\": NO_HSD_QUAR_12,\n",
        "        \"NO_HSD_QUAR_2016\": NO_HSD_QUAR_2016,\n",
        "        \"MED_INC_QUAR_00\": MED_INC_QUAR_00,\n",
        "        \"MED_INC_QUAR_12\": MED_INC_QUAR_12,\n",
        "        \"MED_INC_QUAR_2016\": MED_INC_QUAR_2016,\n",
        "        \"UR_CD_03\": rucc03,\n",
        "        \"UR_CD_13\": rucc13,\n",
        "    }"
      ],
      "metadata": {
        "id": "NznIdl2f-enS"
      },
      "id": "NznIdl2f-enS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction backend for probability of 30d mortality after surgery for HNSCC with ONM\n",
        "\n",
        "# ------------------------------- #\n",
        "# Inference function (Gradio backend)\n",
        "# ------------------------------- #\n",
        "\n",
        "def build_feature_row_from_inputs(\n",
        "    zip_code: str,\n",
        "    year_of_dx: float,\n",
        "    age: float,\n",
        "    crowfly: float,\n",
        "    tumor_size: float,\n",
        "    pos_nodes: float,\n",
        "    nodes_exam: float,\n",
        "    dx_surg_days: float,\n",
        "    dx_defsurg_days: float,\n",
        "    surg_discharge_days: float,\n",
        "    cdcc_label: str,\n",
        "    behavior_label: str,\n",
        "    race_label: str,\n",
        "    sex_label: str,\n",
        "    facility_type_label: str,\n",
        "    clin_stage_label: str,\n",
        "):\n",
        "    # Initialize all features (zeros)\n",
        "    features = {k: 0 for k in selected_features}\n",
        "\n",
        "    # Numerics (with defaults on None/NaN)\n",
        "    def _nz(x, key):  # normalize numeric input to default if blank\n",
        "        return float(x) if x not in (None, \"\", np.nan) else default_values[key]\n",
        "\n",
        "    features[\"YEAR_OF_DIAGNOSIS\"]      = _nz(year_of_dx, \"YEAR_OF_DIAGNOSIS\")\n",
        "    features[\"AGE\"]                    = _nz(age, \"AGE\")\n",
        "    features[\"CROWFLY\"]                = _nz(crowfly, \"CROWFLY\")\n",
        "    features[\"TUMOR_SIZE\"]             = _nz(tumor_size, \"TUMOR_SIZE\")\n",
        "    features[\"TUMOR_SIZE_SUMMARY_16\"]  = features[\"TUMOR_SIZE\"]  # per your spec: use same numeric value\n",
        "    features[\"REGIONAL_NODES_POSITIVE\"]= _nz(pos_nodes, \"REGIONAL_NODES_POSITIVE\")\n",
        "    features[\"REGIONAL_NODES_EXAMINED\"]= _nz(nodes_exam, \"REGIONAL_NODES_EXAMINED\")\n",
        "    features[\"DX_SURG_STARTED_DAYS\"]   = _nz(dx_surg_days, \"DX_SURG_STARTED_DAYS\")\n",
        "    features[\"DX_DEFSURG_STARTED_DAYS\"]= _nz(dx_defsurg_days, \"DX_DEFSURG_STARTED_DAYS\")\n",
        "    features[\"SURG_DISCHARGE_DAYS\"]    = _nz(surg_discharge_days, \"SURG_DISCHARGE_DAYS\")\n",
        "\n",
        "    # Charlson (dropdown '0/1/2/3+'), map to int 0..3 (we’ll cap 3+ -> 3)\n",
        "    cdcc_code = {\"0\": 0, \"1\": 1, \"2\": 2, \"3+\": 3}.get(str(cdcc_label), default_values[\"CDCC_TOTAL_BEST\"])\n",
        "    features[\"CDCC_TOTAL_BEST\"] = cdcc_code\n",
        "\n",
        "    # Behavior (0..3)\n",
        "    features[\"BEHAVIOR\"] = BEHAVIOR_UI_TO_CODE.get(behavior_label, default_values[\"BEHAVIOR\"])\n",
        "\n",
        "    # Race one-hot (White, Black, Other)\n",
        "    for col in (\"RACE_1.0\", \"RACE_2.0\", \"RACE_OTHER\"):\n",
        "        features[col] = 0\n",
        "    for col in RACE_UI_TO_ONEHOT.get(race_label, (\"RACE_OTHER\",)):\n",
        "        features[col] = 1\n",
        "\n",
        "    # Sex one-hot\n",
        "    for col in (\"SEX_1.0\", \"SEX_2.0\"):\n",
        "        features[col] = 0\n",
        "    for col in SEX_UI_TO_ONEHOT.get(sex_label, tuple()):\n",
        "        features[col] = 1\n",
        "\n",
        "    # Facility Type one-hot\n",
        "    for col in (\"FACILITY_TYPE_CD_1.0\", \"FACILITY_TYPE_CD_2.0\",\n",
        "                \"FACILITY_TYPE_CD_3.0\", \"FACILITY_TYPE_CD_4.0\", \"FACILITY_TYPE_CD_nan\"):\n",
        "        features[col] = 0\n",
        "    for col in FACILITY_TYPE_UI_TO_ONEHOT.get(facility_type_label, (\"FACILITY_TYPE_CD_nan\",)):\n",
        "        features[col] = 1\n",
        "\n",
        "    # Clinical Stage Group one-hot\n",
        "    for col in [\n",
        "        'TNM_CLIN_STAGE_GROUP_',\n",
        "        'TNM_CLIN_STAGE_GROUP_   0',\n",
        "        'TNM_CLIN_STAGE_GROUP_   1',\n",
        "        'TNM_CLIN_STAGE_GROUP_   2',\n",
        "        'TNM_CLIN_STAGE_GROUP_   3',\n",
        "        'TNM_CLIN_STAGE_GROUP_   4',\n",
        "        'TNM_CLIN_STAGE_GROUP_  4A',\n",
        "        'TNM_CLIN_STAGE_GROUP_  4B',\n",
        "        'TNM_CLIN_STAGE_GROUP_  4C',\n",
        "        'TNM_CLIN_STAGE_GROUP_  99',\n",
        "    ]:\n",
        "        features[col] = 0\n",
        "    # TODO: set chosen stage’s one-hot (we leave the bare 'TNM_CLIN_STAGE_GROUP_' at 0 unless you later decide to use it)\n",
        "    stage_col = CLIN_STAGE_UI_TO_ONEHOT.get(clin_stage_label, None)\n",
        "    if stage_col:\n",
        "        features[stage_col] = 1\n",
        "\n",
        "    # ZIP → 8 NCDB-style variables (with robust fallbacks)\n",
        "    zip_defaults = {\n",
        "        \"NO_HSD_QUAR_00\": default_values[\"NO_HSD_QUAR_00\"],\n",
        "        \"NO_HSD_QUAR_12\": default_values[\"NO_HSD_QUAR_12\"],\n",
        "        \"NO_HSD_QUAR_2016\": default_values[\"NO_HSD_QUAR_2016\"],\n",
        "        \"MED_INC_QUAR_00\": default_values[\"MED_INC_QUAR_00\"],\n",
        "        \"MED_INC_QUAR_12\": default_values[\"MED_INC_QUAR_12\"],\n",
        "        \"MED_INC_QUAR_2016\": default_values[\"MED_INC_QUAR_2016\"],\n",
        "        \"UR_CD_03\": default_values[\"UR_CD_03\"],\n",
        "        \"UR_CD_13\": default_values[\"UR_CD_13\"],\n",
        "    }\n",
        "    try:\n",
        "        zip_vars = ncdb_zip_to_vars(str(zip_code).strip())\n",
        "    except Exception:\n",
        "        zip_vars = zip_defaults\n",
        "    for k, v in zip_vars.items():\n",
        "        features[k] = int(v) if v is not None else zip_defaults[k]\n",
        "\n",
        "    # Build DataFrame in exact training order\n",
        "    df = pd.DataFrame([[features.get(col, 0) for col in selected_features]], columns=selected_features)\n",
        "\n",
        "    return df\n",
        "\n",
        "DEFAULT_UI = (\n",
        "    \"07605\", 2015, 65, 10, 30, 1, 10, 14, 21, 5, \"0\",\n",
        "    \"Invasive\", \"White\", \"M\", \"Academic/Research Program\", \"Stage 1\",\n",
        ")\n",
        "\n",
        "_DEFAULT_CACHE = {}  # in-memory\n",
        "\n",
        "def warm_cache_default():\n",
        "    try:\n",
        "        df_row = build_feature_row_from_inputs(*DEFAULT_UI)\n",
        "        p = float(stacked_model.predict_proba(df_row)[0, 1])\n",
        "        or_vs_base = odds_ratio_vs_baseline(p, BASELINE_PREVALENCE)\n",
        "        fig = shap_grouped_bar_kernel(stacked_model, df_row, bg_pickle_path=\"ONM-Outcomes/models/shap_background.pkl\")\n",
        "\n",
        "        risk_line = f\"**Predicted 30-day mortality risk:** {p*100:.2f}%\"\n",
        "        or_line   = f\"**Odds ratio vs baseline ({BASELINE_PREVALENCE*100:.2f}%):** {or_vs_base:.2f}×\"\n",
        "        _DEFAULT_CACHE[\"result\"] = (risk_line, or_line, fig)\n",
        "        print(\"[CACHE] default example warmed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"[CACHE] warm failed: {e}\")\n",
        "\n",
        "# call once after model is loaded\n",
        "warm_cache_default()\n",
        "\n",
        "def predict_and_explain(*ui_inputs):\n",
        "    \"\"\"\n",
        "    1) Build model-ready row from UI inputs\n",
        "    2) Predict p(30d mortality)\n",
        "    3) Compute odds ratio vs. baseline\n",
        "    4) Compute grouped SHAP and return bar figure\n",
        "    \"\"\"\n",
        "    # quick cache for the exact default example\n",
        "    if ui_inputs == DEFAULT_UI and \"result\" in _DEFAULT_CACHE:\n",
        "        return _DEFAULT_CACHE[\"result\"]\n",
        "\n",
        "    # 1) Build 1-row df expected by the model (use your current logic)\n",
        "    df_row = build_feature_row_from_inputs(*ui_inputs)\n",
        "\n",
        "    # 2) Probability (works for either a StackingClassifier or any calibrated final model)\n",
        "    p = float(stacked_model.predict_proba(df_row)[0, 1])\n",
        "\n",
        "    # 3) Odds ratio vs baseline\n",
        "    or_vs_base = odds_ratio_vs_baseline(p, BASELINE_PREVALENCE)\n",
        "\n",
        "    # 4) SHAP background & grouped bar\n",
        "    fig = shap_grouped_bar_kernel(stacked_model, df_row, bg_pickle_path=\"ONM-Outcomes/models/shap_background.pkl\")\n",
        "\n",
        "    # Nicely formatted text outputs\n",
        "    risk_line = f\"**Predicted 30-day mortality risk:** {p*100:.2f}%\"\n",
        "    or_line   = f\"**Odds ratio vs baseline ({BASELINE_PREVALENCE*100:.2f}%):** {or_vs_base:.2f}×\"\n",
        "\n",
        "    if ui_inputs == DEFAULT_UI:\n",
        "        _DEFAULT_CACHE[\"result\"] = risk_line, or_line, fig\n",
        "\n",
        "    return risk_line, or_line, fig\n"
      ],
      "metadata": {
        "id": "WBrarT-T-xQT"
      },
      "id": "WBrarT-T-xQT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc4b1e39",
      "metadata": {
        "id": "fc4b1e39"
      },
      "outputs": [],
      "source": [
        "# Gradio Demo\n",
        "\n",
        "# ------------------------------- #\n",
        "# Gradio UI (with default values preselected)\n",
        "# ------------------------------- #\n",
        "demo = gr.Interface(\n",
        "    fn=predict_and_explain,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"ZIP code (5 digits)\", value=\"07605\"),\n",
        "        gr.Number(label=\"Year of Diagnosis of HNSCC\", value=default_values[\"YEAR_OF_DIAGNOSIS\"]),\n",
        "        gr.Number(label=\"Age\", value=default_values[\"AGE\"]),\n",
        "        gr.Number(label=\"Residence Distance to Nearest Hospital (miles)\", value=default_values[\"CROWFLY\"]),\n",
        "        gr.Number(label=\"Tumor Size (nearest mm)\", value=default_values[\"TUMOR_SIZE\"]),\n",
        "        gr.Number(label=\"Number of Positive Regional Nodes\", value=default_values[\"REGIONAL_NODES_POSITIVE\"]),\n",
        "        gr.Number(label=\"Number of Regional Nodes Examined\", value=default_values[\"REGIONAL_NODES_EXAMINED\"]),\n",
        "        gr.Number(label=\"Days from Diagnosis to First Surgery\", value=default_values[\"DX_SURG_STARTED_DAYS\"]),\n",
        "        gr.Number(label=\"Days from Diagnosis to Definitive Surgery\", value=default_values[\"DX_DEFSURG_STARTED_DAYS\"]),\n",
        "        gr.Number(label=\"Days from Surgery to Discharge\", value=default_values[\"SURG_DISCHARGE_DAYS\"]),\n",
        "\n",
        "        gr.Dropdown(choices=[\"0\", \"1\", \"2\", \"3+\"], value=\"0\",\n",
        "                    label=\"Charlson/Deyo Comorbidity Score\"),\n",
        "        gr.Dropdown(choices=list(BEHAVIOR_UI_TO_CODE.keys()), value=\"Invasive\",\n",
        "                    label=\"Behavior of tumor\"),\n",
        "        gr.Dropdown(choices=[\"White\", \"Black\", \"Other\"], value=\"White\",\n",
        "                    label=\"Race\"),\n",
        "        gr.Dropdown(choices=list(SEX_UI_TO_ONEHOT.keys()), value=\"M\",\n",
        "                    label=\"Sex\"),\n",
        "        gr.Dropdown(choices=list(FACILITY_TYPE_UI_TO_ONEHOT.keys()), value=\"Academic/Research Program\",\n",
        "                    label=\"Facility Type\"),\n",
        "        gr.Dropdown(choices=list(CLIN_STAGE_UI_TO_ONEHOT.keys()), value=\"Stage 1\",\n",
        "                    label=\"Clinical Stage Group\"),\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Markdown(label=\"Risk\"),\n",
        "        gr.Markdown(label=\"Odds Ratio vs Baseline\"),\n",
        "        gr.Plot(label=\"Local Explanation (Grouped SHAP)\"),\n",
        "    ],\n",
        "    title=\"30-Day Mortality Risk Predictor (HNSCC, ONM)\",\n",
        "    description=(\n",
        "        \"Predict risk of 30-Day Mortality Using Ensemble Machine Learning Model\"\n",
        "        \"Trained on National Cancer Database\"\n",
        "    ),\n",
        "    allow_flagging=\"never\",\n",
        ")\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "aman",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}